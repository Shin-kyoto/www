{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW01.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyM6F28Lz0bo/OceysKk6Ohm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shin-kyoto/www/blob/develop/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YGoQ5HUea4-",
        "colab_type": "text"
      },
      "source": [
        "#必要なパッケージのインストールとDriveのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKERUU_Nc6tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 必要なパッケージのインストール\n",
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c9N-SYAY2BC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import wordnet as wn #lemmatize関数のためのimport\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNSaTSG-dEmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zskprZ6wDRj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h17IOQ9UHfWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My Drive/Colab Notebooks/M1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ake7VHjIbtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E33KdZ7dawIj",
        "colab_type": "text"
      },
      "source": [
        "#DataFrameの作成\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3248QcpYrtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"./nlp_techwords.csv\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocdrGnwSZKQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2=df.iloc[[3,8],[0,1]]\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncfVBy9-bElz",
        "colab_type": "text"
      },
      "source": [
        "#前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3ndcQM-cGoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_text(text):\n",
        "  def cleaning_text(text):\n",
        "    # @の削除\n",
        "    pattern1 = '@|%'\n",
        "    text = re.sub(pattern1, '', text)    \n",
        "    pattern2 = '\\[[0-9 ]*\\]'\n",
        "    text = re.sub(pattern2, '', text)    \n",
        "    # <b>タグの削除\n",
        "    pattern3 = '\\([a-z ]*\\)'\n",
        "    text = re.sub(pattern3, '', text)    \n",
        "    pattern4 = '[0-9]'\n",
        "    text = re.sub(pattern4, '', text)\n",
        "    #'('または')'の削除\n",
        "    pattern5 ='\\(|\\)' \n",
        "    text = re.sub(pattern5,'',text)\n",
        "    return text\n",
        "  \n",
        "  def tokenize_text(text):\n",
        "    text = re.sub('[.,]', '', text)\n",
        "    return text.split()\n",
        "\n",
        "  def lemmatize_word(word):\n",
        "    # make words lower  example: Python =>python\n",
        "    word=word.lower()\n",
        "    \n",
        "    # lemmatize  example: cooked=>cook\n",
        "    lemma = wn.morphy(word)\n",
        "    if lemma is None:\n",
        "        return word\n",
        "    else:\n",
        "      return lemma\n",
        "    \n",
        "  text = cleaning_text(text)\n",
        "  tokens = tokenize_text(text)\n",
        "  tokens = [lemmatize_word(word) for word in tokens]\n",
        "  tokens = [remove_stopwords(word, en_stop) for word in tokens]\n",
        "  tokens = [word for word in tokens if word is not None]\n",
        "  return tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBLXxIvZdVM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nltkのストップワードリスト\n",
        "en_stop = nltk.corpus.stopwords.words('english')\n",
        "print(en_stop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ws8bfMchDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = df[\"Abstract\"].values\n",
        "pp_docs = [preprocessing_text(text) for text in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvtREU49dZFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp_docs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJzJP0AneM35",
        "colab_type": "text"
      },
      "source": [
        "#集合ベースで文章を表現し，Jaccard係数で類似度計算"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbiS5tDalrFU",
        "colab_type": "text"
      },
      "source": [
        "##集合ベースで文章を表現"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1v1yGLseYHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,doc in zip(range(10),pp_docs):\n",
        "  #execは，文字列をpython文として出力する．\n",
        "  #execを使えば，変数名を定義するときにformatメソッドが使える\n",
        "  exec('set_{}={}'.format(i,set(doc)))\n",
        "  #print('set_{}'.format(i))\n",
        "  #exec('print(set_{})'.format(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQciEdFlxYo",
        "colab_type": "text"
      },
      "source": [
        "##jaccard係数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LmHU_XpjNyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def jaccard_similarity(set_a,set_b):\n",
        "  # 積集合の要素数を計算\n",
        "  num_intersection = len(set.intersection(set_a, set_b))\n",
        "  # 和集合の要素数を計算\n",
        "  num_union = len(set.union(set_a, set_b))\n",
        "  #Jaccard係数を算出　空集合の時は1を出力\n",
        "  try:\n",
        "      return float(num_intersection) / num_union\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0 \n",
        "\n",
        "def dice_similarity(set_a, set_b):\n",
        "  num_intersection =  len(set.intersection(set_a, set_b))\n",
        "  sum_nums = len(set_a) + len(set_b)\n",
        "  try:\n",
        "    return 2 * num_intersection / sum_nums\n",
        "  except ZeroDivisionError:\n",
        "    return 1.0 \n",
        "\n",
        "def simpson_similarity(list_a, list_b):\n",
        "  num_intersection = len(set.intersection(set(list_a), set(list_b)))\n",
        "  min_num = min(len(set(list_a)), len(set(list_b)))\n",
        "  try:\n",
        "    return num_intersection / min_num\n",
        "  except ZeroDivisionError:\n",
        "    if num_intersection == 0:\n",
        "      return 1.0\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02L4afBBmIvR",
        "colab_type": "text"
      },
      "source": [
        "##類似度計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miusOqMcj8Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"jaccard(0, 1) = \", jaccard_similarity(set_0, set_1)) #Jaccard係数を計算"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr8KntdJnOPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sim_1dic(num,sim):\n",
        "  i=num\n",
        "  for j in range(10):\n",
        "    exec('print(\"{}({}, {}) = \",{}_similarity(set_{}, set_{}))'.format(sim,i,j,sim,i,j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la7YypytkJc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1):\n",
        "  for j in range(10):\n",
        "    exec('print(\"jaccard({}, {}) = \",jaccard_similarity(set_{}, set_{}))'.format(i,j,i,j))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtitRHfVniEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_1dic(0,'jaccard')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8E2vcrm7oT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_1dic(0,'dice')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_d5QMWfnMPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sim_1dic(0,'simpson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHA09wcfoc1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num=1\n",
        "sim_1dic(num,'jaccard')\n",
        "sim_1dic(num,'dice')\n",
        "sim_1dic(num,'simpson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85r8J3FEmVJw",
        "colab_type": "text"
      },
      "source": [
        "#ベクトルベースで文章を表現し，TF-IDFベクトルのコサイン類似度表現"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5xc7Ff51aFE",
        "colab_type": "text"
      },
      "source": [
        "##ベクトルベースで文章を表現"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aADvB6i3pEDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bow_vectorizer(docs):\n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "        \n",
        "  result_list = []\n",
        "  for doc in docs:\n",
        "    doc_vec = [0] * len(word2id)\n",
        "    for w in doc:\n",
        "      doc_vec[word2id[w]] += 1\n",
        "    result_list.append(doc_vec)\n",
        "  return result_list, word2id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1hS5ZUvx-Mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_vec, word2id = bow_vectorizer(pp_docs)\n",
        "print(bow_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJP9jCt70YHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(bow_vec[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qy3hnVz2TAI",
        "colab_type": "text"
      },
      "source": [
        "##TF-IDF値を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxxzJd7AzDNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfidf_vectorizer(docs):\n",
        "  def tf(word2id, doc):\n",
        "    term_counts = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      term_counts[word2id[term]] = doc.count(term)\n",
        "    tf_values = list(map(lambda x: x/sum(term_counts), term_counts))\n",
        "    return tf_values\n",
        "  \n",
        "  def idf(word2id, docs):\n",
        "    idf = np.zeros(len(word2id))\n",
        "    for term in word2id.keys():\n",
        "      idf[word2id[term]] = np.log(len(docs) / sum([bool(term in doc) for doc in docs]))\n",
        "    return idf\n",
        "  \n",
        "  word2id = {}\n",
        "  for doc in docs:\n",
        "    for w in doc:\n",
        "      if w not in word2id:\n",
        "        word2id[w] = len(word2id)\n",
        "  \n",
        "  return [[_tf*_idf for _tf, _idf in zip(tf(word2id, doc), idf(word2id, docs))] for doc in docs], word2id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmiQbIcPzOhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vector, word2id = tfidf_vectorizer(pp_docs)\n",
        "print(tfidf_vector)\n",
        "print(word2id.items())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Ikw_mBzVDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(tfidf_vector[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiTRWkXu2dbM",
        "colab_type": "text"
      },
      "source": [
        "##コサイン類似度計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6TDtGqA1WiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(list_a, list_b):\n",
        "  # あとで消す\n",
        "  inner_prod = np.array(list_a).dot(np.array(list_b))\n",
        "  norm_a = np.linalg.norm(list_a)\n",
        "  norm_b = np.linalg.norm(list_b)\n",
        "  try:\n",
        "      return inner_prod / (norm_a*norm_b)\n",
        "  except ZeroDivisionError:\n",
        "      return 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUNuDxnZ4hTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"cosine_similarity(docs[{}], docs[{}]) = \".format(0,1),cosine_similarity(tfidf_vector[0], tfidf_vector[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h9vVr7T5RUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=0\n",
        "for j in range(10):\n",
        "  print(\"cosine_similarity(docs[{}], docs[{}]) = \".format(0,j),cosine_similarity(tfidf_vector[0], tfidf_vector[j]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao0jywXqKIFS",
        "colab_type": "text"
      },
      "source": [
        "# 集合ベースとベクトルベースの比較\n",
        "\n",
        "集合演算の方は一つ一つの文書が小さいデータに対して性能が高い  \n",
        "文書がある程度大きくなるとベクトルベースの方が有用になる  \n",
        "その代わり、語彙集合が大きくなり計算量が大きくなってしまう\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8i_KZYl6a76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#集合ベース\n",
        "num=0\n",
        "sim_1dic(num,'jaccard')\n",
        "sim_1dic(num,'dice')\n",
        "sim_1dic(num,'simpson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plN452s-6WTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ベクトルベース\n",
        "i=0\n",
        "for j in range(10):\n",
        "  print(\"cosine_similarity(docs[{}], docs[{}]) = \".format(0,j),cosine_similarity(tfidf_vector[0], tfidf_vector[j]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}